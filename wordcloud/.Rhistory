fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
library(leaflet)
library(rgdal)
dns <- "/Users/Scarlett/Desktop/Projects/twitter/mapping/USA_shapefile"
fn <- list.files(dns, pattern = ".shp", full.names = FALSE)
fn <- gsub(".shp", "", fn)
dns <- "/Users/Scarlett/Desktop/Projects/twitter/mapping/USA_shapefile"
fn <- list.files(dns, pattern = ".shp", full.names = FALSE)
library(leaflet)
library(rgdal)
dns <- "/Users/Scarlett/Desktop/Projects/twitter/mapping/USA_shapefile"
fn <- list.files(dns, pattern = ".shp", full.names = FALSE)
fn <- gsub(".shp", "", fn)
shape <- readOGR(dns, fn[2])
shape$Population <- state.freq$Freq
i_popup <- paste0("<strong>State: </strong>",
shape$NAME_1,
"<br>",
"<strong>Love Score: </strong>",
shape$Population)
pal <- colorQuantile("PuRd", NULL, n = 5)
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Population),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
View(love.loc)
View(wish.df)
View(wish.df)
load("wish.df.rda")
load("wish.df.rda")
setwd("~/Desktop/Projects/twitter")
load("wish.df.rda")
View(wish.df)
wish.df$text
filterStream( file.name="test1.json",
track = "StuffMyStockingWith",
timeout = 100, oauth=my_oauth)
library(streamR)
load("my_oauth.Rdata")
filterStream( file.name="test1.json",
track = "StuffMyStockingWith",
timeout = 100, oauth=my_oauth)
test1.df <- parseTweets("test1.json")
View(test1.df)
test1.df$text
load("my_oauth.Rdata")
filterStream( file.name="test2.json",
track = "StuffMyStockingWith",
timeout = 100, oauth=my_oauth)
test2.df <- parseTweets("test2.json")
load("my_oauth.Rdata")
filterStream( file.name="test3.json",
track = "love",
timeout = 30, oauth=my_oauth)
test3.df <- parseTweets("test3.json")
View(test3.df)
unique(test3.df$place_lat)
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Population),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
library(tm)
library(SnowballC)
library(wordcloud)
library(cluster)
library(RColorBrewer)
library(plyr)
library(rgdal)
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Population),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Population),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
library("leaflet", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Population),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
library(ROAuth)
library(streamR)
library(tm)
library(SnowballC)
library(wordcloud)
library(cluster)
library(RColorBrewer)
library(plyr)
library(leaflet)
library(rgdal)
source("latlong2state.r")
getwd()
setwd("/Users/Scarlett/Desktop/Projects/twitter")
library(ROAuth)
library(streamR)
library(tm)
library(SnowballC)
library(wordcloud)
library(cluster)
library(RColorBrewer)
library(plyr)
library(leaflet)
library(rgdal)
source("latlong2state.r")
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "IqSkDmnKey0vVc7cVjKHT2n9s"
consumerSecret <- "23H1fGt0I6GUkZru4TSLGOS7PgS7PSlpiOhIlkbMCDFMNx9R9z"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret,
requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
wish.df <- parseTweets("wish.json")
save(wish.df, file = "wish.df.rda")
saveRDS(wish.df, file = "wish.df.rds")
load("wish.df.rds")
saveRDS(wish.df, file = "wish.df.rds")
load("wish.df.rds")
saveRDS(wish.df, file = "wish.df.rds")
load("wish.df.rds")
wish.df <- parseTweets("wish.json")
View(wish.df)
saveRDS(wish.df, file = "wish.df.rds")
load("wish.df.rds")
wish.df.text <- wish.df$text
class(wish.df)
head(wish.df.text)
wish.df.text <- iconv(wish.df.text, "ASCII", "UTF-8", sub = "")
head(wish.df.text)
wish.df.text <- gsub("@\\w+", "", wish.df.text)
head(wish.df.text)
wish.df.text <- gsub("http\\w+", "", wish.df.text)
head(wish.df.text)
clean <- funcion(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean <- funcion(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean <- funcion(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean <- funcion(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean_text <- function(tweets.vector){
if (!is.vector(tweets.vector)){
warning("To trim and analyze tweets, you must input a vector. Input '[*parsed tweets dataframe name*]$text' into function to continue")
}else{
# initialize vector to hold cleaned tweets
clean_tweets <- "empty"
# initialize index variable
i <- 0
# loop through all tweets in dataframe, remove handles and hastags in each
for (tweet in tweets.vector){
i = i + 1
clean_tweets[i] <- trim_tweet(tweet)
}
# convert tweets to dataframe
tweets.df <- data.frame(clean_tweets, stringsAsFactors = FALSE)
# name the column of the new dataframe
colnames(tweets.df) <- c("text")
# return all of the cleaned tweets, as a DATAFRAME
return(tweets.df)
}
}
clean <- funtion(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("http\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("https\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
x <- gsub("https\\w+ *", "", x)
trim_tweet <- function(tweet.text){
# remove handles
clean <- gsub("@\\w+ *", "", tweet.text)
# remove hashtags
clean <- gsub("#\\w+ *", "", tweet.text)
# remove newline character
clean <- gsub("\n", " ", clean)
# we want to get rid of anything that is not a letter, space, or hashtag
# we do not want numbers because they are not text
clean <- gsub("[^a-zA-Z #]","",clean)
# remove URLs
clean <- gsub("https\\w+ *", "", clean)
# send all characters to lowercase
clean <- tolower(clean)
# trim spaces that may have piled up after removing hastags, handles, and URLs
clean <- str_trim(clean, side = "both")
# return the cleaned tweet, as a STRING
return(clean)
}
trim_tweet(wish.df.text)
head(wish.df.text)
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)                       # remove handles
x <- gsub("https\\w+ *", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
x <- wish.df.text
x <- gsub("https\\w+ *", "", x)
head(x)
x <- gsub("https:\\w+ *", "", x)
x <- wish.df.text
head(x)
wish.df.text <- gsub("\\|", "", wish.df.text)
head(wish.df.text)
wish.df.text <- gsub("@\\w+ *", "", wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
wish.df.text <- gsub("@\\w+ *", "", wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
head(wish.df.text)
wish.df.text <- gsub("#\\w+ *", "", wish.df.text)
head(wish.df.text)
wish.df.text <- gsub("https\\w+ *", "", wish.df.text)
head(wish.df.text)
wish.df.text <- gsub("https.*", "", wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@.*", "", x)                # remove handles
x <- gsub("https.*", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@.*", "", x)                # remove handles
x <- gsub("https.*", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@.*", "", x)                # remove handles
x <- gsub("https.*", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@.*", "", x)                # remove handles
x <- gsub("https.*", "", x)
x <- gsub("[:punct:]", "", x)
x <- gsub("\n", "", x)
}
clean(wish.df.text)
head(wish.df.text)
x <- wish.df.text
head(x)
x <- gsub("https.*", "", x)
head(x)
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
head(x)
x <- gsub("@.*", "", x)                # remove handles
head(x)
x <- gsub("[:punct:]", "", x)
head(x)
x <- gsub("\n", "", x)
head(x)
trim_tweet <- function(tweet.text){
x <- gsub("@\\w+ *", "", tweet.text)
# remove hashtags
x <- gsub("#\\w+ *", "", tweet.text)
# remove newline character
x <- gsub("\n", " ", x)
# we want to get rid of anything that is not a letter, space, or hashtag
# we do not want numbers because they are not text
x <- gsub("[^a-zA-Z #]","",x)
# remove URLs
x <- gsub("https\\w+ *", "", x)
# send all characters to lowercase
x <- tolower(x)
# return the cleaned tweet, as a STRING
return(x)
}
trim_tweet(wish.df.text)
gsub('[^0-9]','','htf84756.iuy')
gsub('[0-9]','','htf84756.iuy')
wish.df.text <- wish.df$text
clean <- function(x) {
x <- gsub("@\\w+ *", "", tweet.text)
x <- gsub("#\\w+ *", "", tweet.text)
x <- gsub("https\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- tolower(x)
}
clean(wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- gsub("@\\w+ *", "", x)
x <- gsub("#\\w+ *", "", x)
x <- gsub("https\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- tolower(x)
}
clean(wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
x <- wish.df.text
head(x)
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)
x <- gsub("#\\w+ *", "", x)
x <- gsub("https\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- tolower(x)
}
clean(wish.df.text)
head(wish.df.text)
head(x)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)
x <- gsub("#\\w+ *", "", x)
x <- gsub("https\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- tolower(x)
return(x)
}
clean(wish.df.text)
wish.df.text <- gsub("https\\w+ *", "", wish.df.text)
head(wish.df.text)
wish.df.text <- wish.df$text
x <- wish.df.text
head(x)
x <- gsub("https\\w+ *", "", x)
head(x)
x <- gsub("https\\w+ *", "", x)
head(x)
x <- wish.df.text
head(x)
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)
x <- gsub("#\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- gsub("https\\w+ *", "", x)
x <- tolower(x)
head(x)
wish.df.text <- wish.df$text
clean <- function(x) {
x <- iconv(x, "ASCII", "UTF-8", sub="")    # remove all emojis
x <- gsub("@\\w+ *", "", x)
x <- gsub("#\\w+ *", "", x)
x <- gsub("\n", " ", x)
x <- gsub("[^a-zA-Z #]","",x)    # "a-zA-Z #" are the things we need, [^a-zA-Z #] are the things to get rid of
x <- gsub("https\\w+ *", "", x)
x <- tolower(x)
return(x)
}
wish.df.text <- clean(wish.df.text)
head(wish.df.text)
saveRDS(wish.df.text, file = "wish.df.text.rds")
load("wish.df.text.rds")
wish.df.text <- readRDS("wish.df.text.rds")
save(wish.df.text, file = "wish.df.text.rds")
load("wish.df.text.rds")
wish.df.text
wish.Corpus <- Corpus(VectorSource(wish.df.text))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
wish.Corpus <- Corpus(VectorSource(wish.df.text))
wish.Corpus <- tm_map(wish.Corpus, removeWords, stopwords('english'))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
wish.Corpus <- Corpus(VectorSource(wish.df.text))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
wish.Corpus <- tm_map(wish.Corpus, removeWords, c('the', 'this', "I'm", 'just', 'like', stopwords('english')))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
wish.Corpus <- tm_map(wish.Corpus, removeWords, stopwords('english'))
wish.Corpus <- Corpus(VectorSource(wish.df.text))
wish.Corpus <- tm_map(wish.Corpus, removeWords, stopwords('english'))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
wish.Corpus <- tm_map(wish.Corpus, removeWords, c('just', 'like', 'dont', 'get', 'one', 'amp' stopwords('english')))
wish.Corpus <- Corpus(VectorSource(wish.df.text))
wish.Corpus <- tm_map(wish.Corpus, removeWords, c('just', 'like', 'dont', 'get', 'one', 'amp', stopwords('english')))
wordcloud(wish.Corpus, max.words = 100, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
View(wish.df)
wish.df$text <- wish.df.text
View(wish.df)
load("wish.df.rds")
load("wish.df.rda")
save(wish.df, file = "wish.df.rds")
load("wish.df.rds")
View(wish.df)
load("wish.df.rda")
View(wish.df)
save(wish.df, file = "wish.df.rds")
load("wish.df.rds")
source("latlong2state.r")
library(rgdal)
wish.df$text <- wish.df.text
pos <- grep("love", wish.df$text)
wish.df <- na.omit(wish.df[pos, c(1,15,37,38)])
View(wish.df)
load("wish.df.rds")
load("wish.df.rds")
wish.df$text <- wish.df.text
pos <- grep("love", wish.df$text)
love.df <- na.omit(wish.df[pos, c(1,15,37,38)])
love.loc <- (data.frame(wish.df$place_lon, wish.df$place_lat))
states <- latlong2state(love.loc)
love.df <- na.omit(wish.df[pos, c(1,15,37,38)])
love.loc <- (data.frame(wish.df$place_lon, wish.df$place_lat))
pos <- grep("love", wish.df$text)
love.df <- na.omit(wish.df[pos, c(1,15,37,38)])
love.loc <- (data.frame(love.df$place_lon, love.df$place_lat))
states <- latlong2state(love.loc)
test <- as.data.frame(table(states))
View(test)
freq.table <- as.data.frame(table(states))
dns <- "/Users/Scarlett/Desktop/Projects/twitter/mapping/USA_shapefile"
fn <- list.files(dns, pattern = ".shp", full.names = FALSE)
fn <- gsub(".shp", "", fn)
shape <- readOGR(dns, fn[2])
shape.state <- as.data.frame(tolower(shape$NAME_1))
state.freq <- merge(shape.state, freq.table, by.x = "tolower(shape$NAME_1)", by.y = "states", all = TRUE)
library(leaflet)
library(rgdal)
dns <- "/Users/Scarlett/Desktop/Projects/twitter/mapping/USA_shapefile"
fn <- list.files(dns, pattern = ".shp", full.names = FALSE)
fn <- gsub(".shp", "", fn)
shape <- readOGR(dns, fn[2])
shape$Freq <- state.freq$Freq
i_popup <- paste0("<strong>State: </strong>",
shape$NAME_1,
"<br>",
"<strong>Love Score: </strong>",
shape$Freq)
pal <- colorQuantile("PuRd", NULL, n = 5)
leaflet(shape) %>% addTiles() %>%
setView(-95, 37, zoom = 4) %>%
addPolygons(fillColor = ~pal(shape$Freq),
fillOpacity = 0.8,
color = "#000000",
weight = 1, popup = i_popup)
shape <- readOGR(USA_adm1)
